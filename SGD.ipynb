{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Homework9 SGD experiments\n",
        "**Prepare for Data Generation**"
      ],
      "metadata": {
        "id": "iyJOfF1yeTeg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QrPUVhe4Skhm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "# Specify m, n\n",
        "m = 500\n",
        "n = 50\n",
        "# Specify the mean and variance of noise \\delta, which follows normal distribution.\n",
        "mu = 0\n",
        "# This can be changed.\n",
        "sigma = 0.8\n",
        "np.random.seed(1234)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define a function to generate experimental data.\n",
        "# Input args: m,n are matrix shape; mu and sigma are for noise data.\n",
        "def data_generator(m,n,mu, sigma):\n",
        "    # A is a matrix with size R^{m*n}\n",
        "\n",
        "    A = np.empty([m,n])\n",
        "    # ground truth\n",
        "    z = 10*np.random.rand(n,1)\n",
        "    # create noise vector with the length equals to m\n",
        "    for i in range(m):\n",
        "        for j in range(n):\n",
        "            A[i,j] = np.random.normal(mu, 1)\n",
        "        norm_A_i = np.linalg.norm(A[i,:],2)\n",
        "        # scale each row of A such that the norm of each row is equal to 1.\n",
        "        A[i,:] = A[i,:]/norm_A_i\n",
        "    delta = np.random.normal(mu, sigma, size=(m,1))\n",
        "    return A, z, delta"
      ],
      "metadata": {
        "id": "2OET4ztDTR8b"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A, z, delta = data_generator(m,n,mu,sigma)\n",
        "# generate observations\n",
        "b = np.matmul(A,z)+delta\n",
        "# check about A,z,b's shape\n",
        "print(A.shape)\n",
        "print(z.shape)\n",
        "print(delta.shape)\n",
        "print(b.shape)\n",
        "print(np.linalg.norm(A[1,:],2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yjk-uZHSTXpk",
        "outputId": "ba6c8bc3-59bf-4810-c656-895736fe15a7"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(500, 50)\n",
            "(50, 1)\n",
            "(500, 1)\n",
            "(500, 1)\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement a class for all attributes**\\\n",
        "lr: learning rate\\\n",
        "N: batch size\\\n",
        "theta: momentum parameter\\\n",
        "choic: 0 indicates \"with replacement\", 1 indicates \"without replacement\"\\\n",
        "T: epoch"
      ],
      "metadata": {
        "id": "Y3uZVHwdeevj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class optimizer:\n",
        "  '''\n",
        "  lr: learning rate\n",
        "  N: batch size\n",
        "  theta: momentum parameter\n",
        "  choic: 0 indicates \"with replacement\", 1 indicates \"without replacement\"\n",
        "  T: epoch\n",
        "  '''\n",
        "  def __init__(self):\n",
        "    self.lr = 0.1\n",
        "    self.N = 1\n",
        "    self.theta = 0.1\n",
        "    self.choice = 0\n",
        "    self.T = 10\n",
        "    self.stop_criteria = 1e-1\n",
        "  # set_ function are all functions to change the value.\n",
        "  def set_lr(self,lr):\n",
        "    self.lr = lr\n",
        "\n",
        "  def set_N(self,N):\n",
        "    self.N = N\n",
        "\n",
        "  def set_theta(self,theta):\n",
        "    self.theta = theta\n",
        "\n",
        "  def set_choice(self,choice):\n",
        "    self.choice = choice\n",
        "  def set_T(self,T):\n",
        "    self.T = T\n",
        "\n",
        "  # define a function compute least square loss function value.\n",
        "  def least_square(self,A,x,b):\n",
        "    m,n = A.shape\n",
        "    residual = np.matmul(A,x)-b\n",
        "    loss = 0.5*(1/m)*np.linalg.norm(residual,2)**2\n",
        "    return loss\n",
        "  # define a function compute gradient\n",
        "\n",
        "  def grad(self,A,x,b):\n",
        "    residual = np.matmul(A,x)-b\n",
        "    # gradient is A^T(Ax-b)\n",
        "    grad = np.matmul(np.transpose(A),residual)\n",
        "    return grad\n",
        "\n",
        "  # define a function to sample the mini_batch of data.\n",
        "  def mini_batch_sampling(self,A,b):\n",
        "    m,n = A.shape\n",
        "    # sampling with replacement\n",
        "    if self.choice == 0:\n",
        "      indx = np.random.choice(m, size=self.N, replace=True)\n",
        "      batch_A = A[indx,:]\n",
        "      batch_b = b[indx,:]\n",
        "    # sampling without replacement\n",
        "    if self.choice == 1:\n",
        "      indx = np.random.choice(m, size=self.N, replace=False)\n",
        "      np.random.shuffle(indx)\n",
        "      batch_A = A[indx,:]\n",
        "      batch_b = b[indx,:]\n",
        "    return batch_A, batch_b\n",
        "\n",
        "  # function to implement SGD.(for sampling with or without replacement)\n",
        "  def sgd(self,A,b,x):\n",
        "    m,n = A.shape\n",
        "    count = 0\n",
        "    stop = 100\n",
        "    while (count <= self.T) and (stop >= self.stop_criteria):\n",
        "      batch_A, batch_b = self.mini_batch_sampling(A,b)\n",
        "      m1,n1 = batch_A.shape\n",
        "      grad = (1/m1)*self.grad(batch_A,x,batch_b)\n",
        "      stop = np.linalg.norm(grad)\n",
        "      x += -self.lr*grad\n",
        "      count += 1\n",
        "    return x, count\n",
        "  # function to implement sgd with average.\n",
        "  def sgd_average(self,A,b,x):\n",
        "    m,n = A.shape\n",
        "    count = 0\n",
        "    stop = 100\n",
        "    x_list = []\n",
        "    x_list.append(x)\n",
        "    while (count <= self.T) and (stop >= self.stop_criteria):\n",
        "      batch_A, batch_b = self.mini_batch_sampling(A,b)\n",
        "      m1,n1 = batch_A.shape\n",
        "      grad = (1/m1)*self.grad(batch_A,x,batch_b)\n",
        "      stop = np.linalg.norm(grad)\n",
        "      x += -self.lr*grad\n",
        "      x_list.append(x)\n",
        "      count += 1\n",
        "      # return average\n",
        "    return np.mean(np.array(x_list),axis=0), count\n",
        "  # function to implement sgd with momentum acceleration.\n",
        "  def sgd_momentum(self,A,b,x):\n",
        "    count = 0\n",
        "    m,n = A.shape\n",
        "    momentum = np.zeros((n,1))\n",
        "    stop = 100\n",
        "    while (count <= self.T) and (stop >= self.stop_criteria):\n",
        "      batch_A, batch_b = self.mini_batch_sampling(A,b)\n",
        "      m1,n1 = batch_A.shape\n",
        "      grad = (1/m1)*self.grad(batch_A,x,batch_b)\n",
        "      stop = np.linalg.norm(grad)\n",
        "      # momentum update\n",
        "      momentum = self.theta*momentum - self.lr*grad\n",
        "      x += momentum\n",
        "      count += 1\n",
        "    return x,count\n",
        "  # function to implement gd with momentum.\n",
        "  def gd_momentum(self,A,x,b):\n",
        "    count = 0\n",
        "    # initialization\n",
        "    m,n = A.shape\n",
        "    momentum =np.zeros((n,1))\n",
        "    stop = 100\n",
        "    grad = self.grad(A,x,b)\n",
        "    while (count <= self.T) and (stop >= self.stop_criteria):\n",
        "      grad = (1/m)*self.grad(A,x,b)\n",
        "      stop = np.linalg.norm(grad)\n",
        "      momentum = self.theta*momentum - self.lr*grad\n",
        "      x += momentum\n",
        "      count += 1\n",
        "    return x,count\n",
        "\n"
      ],
      "metadata": {
        "id": "xaEYiwmxTcOn"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test case for simulation I**"
      ],
      "metadata": {
        "id": "Qyk2Wr2Yfs5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate initial guess\n",
        "# set class hyperparameter.\n",
        "opt = optimizer()\n",
        "opt.set_lr(1)\n",
        "opt.set_N(10)\n",
        "opt.set_T(10000)\n",
        "opt.set_theta(0.5)\n",
        "x0 = z+5*np.random.normal(0,1,size = (z.shape[0],z.shape[1]))\n",
        "\n",
        "# with replacement\n",
        "x_gd,iter_gd = opt.gd_momentum(A,x0,b)\n",
        "obj_val0 = opt.least_square(A,x_gd,b)\n",
        "sample_gd = m * iter_gd\n",
        "print('gradient descent+momentum,objective value:%f,samples:%d'%(obj_val0,sample_gd))\n",
        "opt.set_choice(0)\n",
        "x_sgd,iter_sgd = opt.sgd(A,b,x0)\n",
        "obj_val1 = opt.least_square(A,x_sgd,b)\n",
        "sample_sgd = opt.N * iter_sgd\n",
        "print('sgd sampling with replacement,objective value:%f,samples:%d'%(obj_val1,sample_sgd))\n",
        "\n",
        "x_avg_sgd,iter_avg_sgd = opt.sgd_average(A,b,x0)\n",
        "obj_val2 = opt.least_square(A,x_avg_sgd,b)\n",
        "sample_sgd_avg = opt.N * iter_avg_sgd\n",
        "print('sgd with replacement + averaging,objective value:%f,samples:%d'%(obj_val2,sample_sgd_avg))\n",
        "\n",
        "x_sgd_mom,iter_sgd_mom = opt.sgd_momentum(A,b,x0)\n",
        "obj_val3 = opt.least_square(A,x_sgd_mom,b)\n",
        "sample_sgd_mom = opt.N * iter_sgd_mom\n",
        "print('sgd with replacement + momentum,objective value:%f, samples: %d'%(obj_val3,sample_sgd_mom))\n",
        "\n",
        "\n",
        "# without replacement\n",
        "opt.set_choice(1)\n",
        "\n",
        "x_sgd1,iter_sgd1 = opt.sgd(A,b,x0)\n",
        "obj_val11 = opt.least_square(A,x_sgd,b)\n",
        "sample_sgd1 = opt.N * iter_sgd1\n",
        "print('sgd without replacement,objective value:%f,samples:%d'%(obj_val11,sample_sgd1))\n",
        "\n",
        "x_avg_sgd1,iter_avg_sgd1 = opt.sgd_average(A,b,x0)\n",
        "obj_val21 = opt.least_square(A,x_avg_sgd,b)\n",
        "sample_sgd_avg1 = opt.N * iter_avg_sgd1\n",
        "print('sgd without replacement + iterative averaging,objective value:%f,samples:%d'%(obj_val21,sample_sgd_avg1))\n",
        "\n",
        "x_sgd_mom1,iter_sgd_mom1 = opt.sgd_momentum(A,b,x0)\n",
        "obj_val31 = opt.least_square(A,x_sgd_mom,b)\n",
        "sample_sgd_mom1 = opt.N * iter_sgd_mom1\n",
        "print('sgd without replacement + momentum,objective value:%f,samples:%d'%(obj_val31,sample_sgd_mom1))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uK1NeleFTkvg",
        "outputId": "23e1f7bd-6251-421e-f66a-a99b24d72c5e"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gradient descent+momentum,objective value:0.543773,samples:23000\n",
            "sgd sampling with replacement,objective value:0.300546,samples:1010\n",
            "sgd with replacement + averaging,objective value:0.285728,samples:2240\n",
            "sgd with replacement + momentum,objective value:0.305379, samples: 6180\n",
            "sgd without replacement,objective value:0.290193,samples:400\n",
            "sgd without replacement + iterative averaging,objective value:0.285728,samples:280\n",
            "sgd without replacement + momentum,objective value:0.295782,samples:3040\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test case for simulation 2**"
      ],
      "metadata": {
        "id": "-T38y4n-fwr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulation 2\n",
        "B_set = [1, 10, 50, 100, 150,200,250,300,350,400,500]\n",
        "x0 = z+5*np.random.normal(0,1,size = (z.shape[0],z.shape[1]))\n",
        "alpha = 2e-3\n",
        "opt2 = optimizer()\n",
        "opt2.set_choice(0)\n",
        "for batch_size in B_set:\n",
        "  opt2.set_N(batch_size)\n",
        "  lr = batch_size*alpha\n",
        "  opt2.set_lr(lr)\n",
        "  x_sgd, iter_sgd = opt2.sgd(A,b, x0)\n",
        "  sample_size = iter_sgd*batch_size\n",
        "  obj_val = opt2.least_square(A,x_sgd,b)\n",
        "  print('learning rate is: %f, objective value is :%f, sample size:%d'%(lr, obj_val,sample_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_bdF7U5aFRS",
        "outputId": "e4ec908a-f6ff-4323-9edc-80066dc45691"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "learning rate is: 0.002000, objective value is :11.836279, sample size:11\n",
            "learning rate is: 0.020000, objective value is :11.723547, sample size:110\n",
            "learning rate is: 0.100000, objective value is :11.183717, sample size:550\n",
            "learning rate is: 0.200000, objective value is :10.130944, sample size:1100\n",
            "learning rate is: 0.300000, objective value is :8.815433, sample size:1650\n",
            "learning rate is: 0.400000, objective value is :7.325047, sample size:2200\n",
            "learning rate is: 0.500000, objective value is :5.874710, sample size:2750\n",
            "learning rate is: 0.600000, objective value is :4.533164, sample size:3300\n",
            "learning rate is: 0.700000, objective value is :3.370679, sample size:3850\n",
            "learning rate is: 0.800000, objective value is :2.483235, sample size:4400\n",
            "learning rate is: 1.000000, objective value is :1.733151, sample size:5500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wQ7RPWupbGn4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}